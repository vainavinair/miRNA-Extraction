{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    \"\"\"Helper function to read files with proper column handling\"\"\"\n",
    "    try:\n",
    "        # Read file content\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read().strip()\n",
    "        \n",
    "        # Check for \"No Available results.\"\n",
    "        if \"No Available results.\" in content:\n",
    "            return None, True\n",
    "        \n",
    "        # Process file normally\n",
    "        lines = [line.strip() for line in content.split('\\n') if line.strip()]\n",
    "        data_lines = [line for line in lines if not line.startswith('#')]\n",
    "        \n",
    "        if not data_lines:\n",
    "            return pd.DataFrame(), False\n",
    "        \n",
    "        # Process lines and split by tabs\n",
    "        processed_data = []\n",
    "        for line in data_lines:\n",
    "            row = [col.strip() for col in line.split('\\t') if col.strip()]\n",
    "            if row:\n",
    "                processed_data.append(row)\n",
    "        \n",
    "        if processed_data:\n",
    "            max_cols = max(len(row) for row in processed_data)\n",
    "            padded_data = [row + [''] * (max_cols - len(row)) for row in processed_data]\n",
    "            df = pd.DataFrame(padded_data[1:], columns=padded_data[0] if padded_data else [f'Column_{i}' for i in range(max_cols)])\n",
    "            return df, False\n",
    "            \n",
    "        return pd.DataFrame(), False\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error reading file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(files_batch, download_dir):\n",
    "    \"\"\"Process a batch of files and return extracted data and results\"\"\"\n",
    "    no_results_files = []\n",
    "    error_files = []\n",
    "    extracted_data = pd.DataFrame(columns=['Column_B', 'Column_D'])\n",
    "    \n",
    "    for filename in files_batch:\n",
    "        try:\n",
    "            file_path = os.path.join(download_dir, filename)\n",
    "            \n",
    "            # Process file\n",
    "            df, is_no_results = read_file(file_path)\n",
    "            \n",
    "            if is_no_results:\n",
    "                no_results_files.append(filename)\n",
    "            elif df is not None and not df.empty:\n",
    "                if 'miRNAname' in df.columns and 'geneName' in df.columns and 'geneType' in df.columns:\n",
    "                    lncrna_rows = df[df['geneType'] == \"lncRNA\"]\n",
    "                    if not lncrna_rows.empty:\n",
    "                        temp_df = lncrna_rows[['miRNAname', 'geneName']]\n",
    "                        temp_df.columns = ['Column_B', 'Column_D']\n",
    "                        extracted_data = pd.concat([extracted_data, temp_df], ignore_index=True)\n",
    "            \n",
    "            # Delete the processed file\n",
    "            os.remove(file_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_files.append(filename)\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "    \n",
    "    return extracted_data, no_results_files, error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_process_mirna(excel_path, batch_size=50):\n",
    "    \"\"\"Main function to download and process miRNA files in batches\"\"\"\n",
    "    # Read input Excel file\n",
    "    df = pd.read_excel(excel_path)\n",
    "    miRNAs = df['miRNA'].dropna().unique()\n",
    "    \n",
    "    # Create download directory\n",
    "    download_dir = 'downloaded_files'\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    \n",
    "    # Create output directory\n",
    "    output = 'output'\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "\n",
    "    # Initialize result storage\n",
    "    all_extracted_data = pd.DataFrame(columns=['Column_B', 'Column_D'])\n",
    "    all_no_results = []\n",
    "    all_errors = []\n",
    "    \n",
    "    # Calculate number of batches\n",
    "    num_batches = math.ceil(len(miRNAs) / batch_size)\n",
    "    \n",
    "    # Process in batches\n",
    "    for batch_num in tqdm(range(num_batches), desc='Processing batches'):\n",
    "        start_idx = batch_num * batch_size\n",
    "        end_idx = min((batch_num + 1) * batch_size, len(miRNAs))\n",
    "        batch_miRNAs = miRNAs[start_idx:end_idx]\n",
    "        \n",
    "        # Download batch\n",
    "        downloaded_files = []\n",
    "        for miRNA in tqdm(batch_miRNAs, desc=f'Downloading batch {batch_num + 1}/{num_batches}', leave=False):\n",
    "            try:\n",
    "                url = f'https://rnasysu.com/encori/moduleDownload.php?source=agoClipRNA&type=xls&value=hg38;lncRNA;{miRNA};1;0;0;1;None;all'\n",
    "                response = requests.get(url)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                filename = f\"{miRNA.replace('/', '_')}.xls\"\n",
    "                file_path = os.path.join(download_dir, filename)\n",
    "                \n",
    "                with open(file_path, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "                downloaded_files.append(filename)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {miRNA}: {str(e)}\")\n",
    "        \n",
    "        # Process batch\n",
    "        extracted_data, no_results, errors = process_batch(downloaded_files, download_dir)\n",
    "        \n",
    "        # Accumulate results\n",
    "        if not extracted_data.empty:\n",
    "            all_extracted_data = pd.concat([all_extracted_data, extracted_data], ignore_index=True)\n",
    "        all_no_results.extend(no_results)\n",
    "        all_errors.extend(errors)\n",
    "    \n",
    "    # Save final results\n",
    "    if all_no_results:\n",
    "        pd.DataFrame({'Filename': all_no_results}).to_excel('output/data_not_found.xlsx', index=False)\n",
    "        print(f\"\\nSaved {len(all_no_results)} files to data_not_found.xlsx\")\n",
    "    \n",
    "    if all_errors:\n",
    "        pd.DataFrame({'Filename': all_errors}).to_excel('output/error_files.xlsx', index=False)\n",
    "        print(f\"\\nSaved {len(all_errors)} problematic files to error_files.xlsx\")\n",
    "    \n",
    "    if not all_extracted_data.empty:\n",
    "        all_extracted_data.to_excel('output/extracted_data.xlsx', index=False)\n",
    "        print(f\"\\nSaved {len(all_extracted_data)} rows to extracted_data.xlsx\")\n",
    "    \n",
    "    # Clean up download directory if empty\n",
    "    if not os.listdir(download_dir):\n",
    "        os.rmdir(download_dir)\n",
    "    \n",
    "    return len(all_no_results), len(all_extracted_data), len(all_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb66664aba2d4629a38a172d7e973093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d272fd2de54bfdaaf49bc158aedfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading batch 1/11:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205d92c2c18042309ace8716a138686f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading batch 2/11:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b41716c06b4d1787980aa099ed2eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading batch 3/11:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading hsa-miR-3942-3p: HTTPSConnectionPool(host='rnasysu.com', port=443): Max retries exceeded with url: /encori/moduleDownload.php?source=agoClipRNA&type=xls&value=hg38;lncRNA;hsa-miR-3942-3p;1;0;0;1;None;all (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000248FEE66CF0>, 'Connection to rnasysu.com timed out. (connect timeout=None)'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d643c934aaaa4755b421b010eca7ba58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading batch 4/11:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e16a9d1f3f94c819270715c418fc12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading batch 5/11:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd4855cab8446758aad8f7c22a1e566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading batch 6/11:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8777f0672f934987b5d9cf2acf3b8bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading batch 7/11:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f1c9118316462788795a9cb9bca108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading batch 8/11:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading hsa-miR-7850-5p: HTTPSConnectionPool(host='rnasysu.com', port=443): Max retries exceeded with url: /encori/moduleDownload.php?source=agoClipRNA&type=xls&value=hg38;lncRNA;hsa-miR-7850-5p;1;0;0;1;None;all (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000248FEE75BB0>, 'Connection to rnasysu.com timed out. (connect timeout=None)'))\n"
     ]
    }
   ],
   "source": [
    "# Execute the combined process\n",
    "no_results_count, extracted_rows, error_count = download_and_process_mirna('get_id.xlsx', batch_size=20)\n",
    "\n",
    "print(f\"\\nProcessing complete!\")\n",
    "print(f\"Files with no results: {no_results_count}\")\n",
    "print(f\"Files with errors: {error_count}\")\n",
    "print(f\"Total rows extracted: {extracted_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
